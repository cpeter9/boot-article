\documentclass[twoside]{article}

\usepackage[round]{natbib}

\usepackage{amsmath}
\makeatletter
\newcommand*\if@single[3]{%
  \setbox0\hbox{${\mathaccent"0362{#1}}^H$}%
  \setbox2\hbox{${\mathaccent"0362{\kern0pt#1}}^H$}%
  \ifdim\ht0=\ht2 #3\else #2\fi
  }
%The bar will be moved to the right by a half of \macc@kerna, which is computed by amsmath:
\newcommand*\rel@kern[1]{\kern#1\dimexpr\macc@kerna}
%If there's a superscript following the bar, then no negative kern may follow the bar;
%an additional {} makes sure that the superscript is high enough in this case:
\newcommand*\widebar[1]{\@ifnextchar^{{\wide@bar{#1}{0}}}{\wide@bar{#1}{1}}}
%Use a separate algorithm for single symbols:
\newcommand*\wide@bar[2]{\if@single{#1}{\wide@bar@{#1}{#2}{1}}{\wide@bar@{#1}{#2}{2}}}
\newcommand*\wide@bar@[3]{%
  \begingroup
  \def\mathaccent##1##2{%
%If there's more than a single symbol, use the first character instead (see below):
    \if#32 \let\macc@nucleus\first@char \fi
%Determine the italic correction:
    \setbox\z@\hbox{$\macc@style{\macc@nucleus}_{}$}%
    \setbox\tw@\hbox{$\macc@style{\macc@nucleus}{}_{}$}%
    \dimen@\wd\tw@
    \advance\dimen@-\wd\z@
%Now \dimen@ is the italic correction of the symbol.
    \divide\dimen@ 3
    \@tempdima\wd\tw@
    \advance\@tempdima-\scriptspace
%Now \@tempdima is the width of the symbol.
    \divide\@tempdima 10
    \advance\dimen@-\@tempdima
%Now \dimen@ = (italic correction / 3) - (Breite / 10)
    \ifdim\dimen@>\z@ \dimen@0pt\fi
%The bar will be shortened in the case \dimen@<0 !
    \rel@kern{0.6}\kern-\dimen@
    \if#31
      \overline{\rel@kern{-0.6}\kern\dimen@\macc@nucleus\rel@kern{0.4}\kern\dimen@}%
      \advance\dimen@0.4\dimexpr\macc@kerna
%Place the combined final kern (-\dimen@) if it is >0 or if a superscript follows:
      \let\final@kern#2%
      \ifdim\dimen@<\z@ \let\final@kern1\fi
      \if\final@kern1 \kern-\dimen@\fi
    \else
      \overline{\rel@kern{-0.6}\kern\dimen@#1}%
    \fi
  }%
  \macc@depth\@ne
  \let\math@bgroup\@empty \let\math@egroup\macc@set@skewchar
  \mathsurround\z@ \frozen@everymath{\mathgroup\macc@group\relax}%
  \macc@set@skewchar\relax
  \let\mathaccentV\macc@nested@a
%The following initialises \macc@kerna and calls \mathaccent:
  \if#31
    \macc@nested@a\relax111{#1}%
  \else
%If the argument consists of more than one symbol, and if the first token is
%a letter, use that letter for the computations:
    \def\gobble@till@marker##1\endmarker{}%
    \futurelet\first@char\gobble@till@marker#1\endmarker
    \ifcat\noexpand\first@char A\else
      \def\first@char{}%
    \fi
    \macc@nested@a\relax111{\first@char}%
  \fi
  \endgroup
}
\makeatother
\newcommand\test[1]{%
$#1{M}$ $#1{A}$ $#1{g}$ $#1{\beta}$ $#1{\mathcal A}^q$
$#1{AB}^\sigma$ $#1{H}^C$ $#1{\sin z}$ $#1{W}_n$}

% \bibpunct{(}{)}{;}{a}{}{,}


\usepackage{lipsum} % Package to generate dummy text throughout this template

\usepackage[sc]{mathpazo} % Use the Palatino font
\usepackage[T1]{fontenc} % Use 8-bit encoding that has 256 glyphs
\linespread{1.05} % Line spacing - Palatino needs more space between lines
\usepackage{microtype} % Slightly tweak font spacing for aesthetics

\usepackage[hmarginratio=1:1,top=32mm,columnsep=20pt]{geometry} % Document margins
\usepackage{multicol} % Used for the two-column layout of the document
\usepackage{hyperref} % For hyperlinks in the PDF

\usepackage[hang, small,labelfont=bf,up,textfont=it,up]{caption} % Custom captions under/above floats in tables or figures
\usepackage{booktabs} % Horizontal rules in tables
\usepackage{float} % Required for tables and figures in the multi-column environment - they need to be placed in specific locations with the [H] (e.g. \begin{table}[H])

\usepackage{lettrine} % The lettrine is the first enlarged letter at the beginning of the text
\usepackage{paralist} % Used for the compactitem environment which makes bullet points with less space between them

\usepackage{abstract} % Allows abstract customization
\renewcommand{\abstractnamefont}{\normalfont\bfseries} % Set the "Abstract" text to bold
% \renewcommand{\abstracttextfont}{\normalfont\small\itshape} % Set the abstract itself to small italic text

\usepackage{titlesec} % Allows customization of titles
\renewcommand\thesection{\Roman{section}}
\titleformat{\section}[block]{\large\scshape\centering}{\thesection.}{1em}{} % Change the look of the section titles

\usepackage{fancyhdr} % Headers and footers
\pagestyle{fancy} % All pages have headers and footers
\fancyhead{} % Blank out the default header
\fancyfoot{} % Blank out the default footer
\fancyhead[C]{On Solving Applied Inference Problems Using Bootstrap and Simulation Models} % Custom header text
\fancyfoot[RO,LE]{\thepage} % Custom footer text

%----------------------------------------------------------------------------------------
%  TITLE SECTION
%----------------------------------------------------------------------------------------

\title{\vspace{-15mm}\fontsize{24pt}{10pt}\selectfont\textbf{On Solving Applied Inference Problems Using Bootstrap and Simulation Models}} % Article title

\author{
\large
\textsc{Christopher Peters}\thanks{Christopher P. Peters is Data Scientist, Treehouse Inc., 622 E. Washington Street Suite 240, Orlando, Florida 32801, USA and Master's of Applied Statistics student, Louisiana State University, 161 Martin D. Woodin Hall, LSU Baton Rouge, Louisiana 70803}\\[2mm] % Your name
\normalsize Louisiana State University \\ % Your institution
\normalsize \href{mailto:cpeter9@gmail.com}{cpeter9@gmail.com} % Your email address
\vspace{-5mm}
}
\date{}

%----------------------------------------------------------------------------------------



<<set-options, include=FALSE, cache=FALSE>>=
opts_chunk$set(dev='tikz', fig.align='center', cache=TRUE, message=FALSE, background='white')
options(replace.assign=TRUE,width=85)
knit_hooks$set(fig=function(before, options, envir){if (before) par(mar=c(4,4,.1,.1),cex.lab=.95,cex.axis=.9,mgp=c(2,.7,0),tcl=-.3)})
library(ggplot2)
theme_set(theme_grey(base_size = 9))
@


\begin{document}


\maketitle % Insert title

\thispagestyle{fancy} % All pages have headers and footers

%----------------------------------------------------------------------------------------
%  ABSTRACT
%----------------------------------------------------------------------------------------

\begin{abstract}

\noindent Much of what young statisticians in training learn in undergraduate and graduate school relies on large-sample asymptotic theory.  Well known statistics are calculated and with a few assumptions a standard error is developed to measure inference reliability.  Unfortunately data are not always sufficiently large such that finite sample properties match those required by large-sample asymptotics.  Additionally a careful examination of assumptions is always required for successful inference.  In some cases common checks of assumptions may not be possible with a high degree of power, especially in cases of  small samples.  One common solution to this problem involves resampling data with replacement to empirically calculate the variance of any statistic.  This solution is generally referred to as bootstrapping.  In addition to its uses for inference, variations on boostrapping methods can be used to simulate data for cross-validation or other purposes.  This article will focus on three applications of boostrapping.  The first is verification of power calculations for a simple experiment.  The second involves inference in the presence of heteroskedasticity.  The third focuses on bootstrapping for cross-validation.

\end{abstract}

%----------------------------------------------------------------------------------------
%	ARTICLE CONTENTS
%----------------------------------------------------------------------------------------

\section{Verification of power calculations}

Power calculations are generally considered good pre-requisite for any designed experiment.  Such calculations allow researchers to determine reasonable sample size requirements before carrying out an experiment.  Such calculations can help researchers avoid carrying out experiments doomed in the sense of statistical detection before experimentation begins.\\ 

The following example takes a look at how power calculations can be carried out and verified by bootstrapping sample data.  In this case a web app company wants to perform an experiment on a business practice.  The company has found a relationship between earning tokens on the site and customer longevity and financial value.  The company decides that it would like to encourage its customers to earn more tokens by sending an email.  However, the company would also like to compare the effect of the email against a control group of customers that did not receive the email.  A two-sample t-test is selected to test for a difference between the mean number of tokens earned in the experiment group and control group.\\

A major assumption underlying the two-sample t-test is that the two samples from come from normally distributed populations.  When this assumption is violated, distribution-free tests such as the Wilcoxon-Mann-Whitney (WMW or Mann-Witney U) test are commonly used~\citep{skovlund}. It is well known that the two-sample t-test is robust to departures from normality when data are large, but how large?

Suppose that we collect data on token earning prior to our experiment.  In this case the data from two randomly selected groups looks as is shown in Figure~\ref{prob_1_raw_data} in Appendix A.  The data are clearly right skewed and look F, Chi-square, or exponentially distributed. While the t-test is usually robust to departures from normality in large samples, it is costly for the company to run large experiments.  Using bootstrapping, we can resample data from the same data stream that will record the effect of the experiment.  This will allow us to take thousands of samples for varying samples sizes in order to compare power and Type I error rates between the two methods.  The two-sample t-test with pooled variances and with separate variances is also analyzed.  By bootstrapping we are granted a look at the robustness of the two-sample t-test for this data with respect to sample size and when it should be preferred to the WMW test.\\

The standard two-sample t-test is shown below:

\begin{align}
t &= \frac{\widebar{Y_1} - \widebar{Y_2}}{s_p\sqrt{\frac{1}{n_1} + \frac{1}{n_2}}}
\end{align}

The WMW statistic is calculated as follow:

\begin{align}
W &= \frac{\sum_{i=0}^{m-1}\sum_{j=0}^{n-1}I(x_i, y_j)}{mn}\\
I(x_i, y_i) &= 
\end{align}

The following bootstrapping procedure was carried out.
\begin{enumerate}
\item Take two random samples of the token data with replacement with sample size thirty each.
\item Take the mean of the differences between the two samples.
\item Repeat steps 1 and 2 {\it B} times.  In this case 2,000 bootstrap samples were taken for each sample and 2,000 mean differences were calculated.
\item Plot a histogram of the mean differences against a theoretical normal and t distributions.
\end{enumerate}

The results in Figure~\ref{prob_1_means} in Appendix A show that the mean differences are indeed normally distributed.  The histogram of mean differences appears to visually approximate a normal distribution.  Increasing the number of bootstrap samples taken causes the histogram to converge to normal with no recognizable difference.  Therefore, the assumption of normality is met in this case of two-sample t-test.\\

Many statistical tools such as analysis of variance and linear regression require assumptions of normality.  If these assumptions are not met these tools are not valid and may be biased without further transformation of data or adjustments to standard errors.  Bootstrapping is a simple way, often overlooked, to check distributional assumptions.  The general procedure is simple:\\

\begin{enumerate}
\item Randomly sample data of interest with replacement B times (generally 1,000 samples is enough).
\item Calculate and save the statistic of interest for each sample.
\item Look at the histogram of that statistic.  If it's normally distributed, calculate the standard deviation of the statistic across all samples to obtain the standard error of the statistic.
\end{enumerate}

Another assumption requred for the two-sample t-test to be valid is that the standard deviation of the differences is $\chi^{2}$ distributed with posi

Though we've 

One simple tool for power calculations is the~\href{http://cran.r-project.org/web/packages/pwr/index.html}{pwr} package found in the R language.



\section{Inference in the presence of heteroskedasticity}

\section{Bootstrapping for cross-validation}


~\citep{Nobody06}.

\bibliography{boot_biblio}{}
\bibliographystyle{plainnat}

\newpage
\section{Appendix A}

\begin{figure}[h!]
<<fig_1, echo=FALSE, fig=TRUE, sanitize=TRUE, out.width='5in', cache=TRUE>>=
library(ggplot2)
library(reshape2)
library(tikzDevice)

data <- read.csv("C:/R_stuff/school/article/data.csv")


sample_a <- sample(table(data$user_id), 400, replace = TRUE)
sample_b <- sample(table(data$user_id), 400, replace = TRUE)

raw.samples <- as.data.frame(t(rbind(sample_a, sample_b)))
raw.samples <- melt(raw.samples)

ggplot(raw.samples, aes(x = value)) +
  geom_histogram(aes(y = ..density..)) +
  facet_grid(variable ~ . )
@
\caption{test caption}
\label{prob_1_raw_data}
\end{figure}

\begin{figure}[h!]
<<fig_2, echo=FALSE, fig=TRUE, sanitize=TRUE, out.width='5in', warning=FALSE, cache=TRUE>>=
library(ggplot2)
library(reshape2)
library(tikzDevice)

data <- read.csv("C:/R_stuff/school/article/data.csv")

# Take differences from B sample groups
B <- 2000
sample.size <- 30
sample_diff <- rep(NA, B)
for(i in 1:B){
  set.seed(i)
  sample_a <- sample(table(data$user_id), sample.size, replace = TRUE)
  sample_b <- sample(table(data$user_id), sample.size, replace = TRUE)
  sample_diff[i] <- mean(sample_a - sample_b)
}

# Convert badge means to a data.frame
sample_diff <- as.data.frame(sample_diff)

# Now lets check if it's t-distributed centered on mean(badge.means), looks normal distributed or t-dist with infinite DF
t <- rt(10000, df = sample.size, ncp = mean(sample_diff))

library(ggplot2)
ggplot(sample_diff, aes(x = sample_diff)) +
  geom_histogram(aes(y = ..density..)) +
  stat_function(fun = dt,
                args = c(df = sample.size,
                         ncp = mean(sample_diff$sample_diff)),
                colour = "red") +
  stat_function(fun = dnorm,
                args = c(mean = mean(sample_diff$sample_diff),
                         sd = sd(sample_diff$sample_diff)),
                colour = "blue") +
  ggtitle("Histogram of mean badges earned within two weeks of membership\nplotted against theoretical t-distribution (red) and normal distribution (blue)")
@
\caption{test caption}
\label{prob_1_means}
\end{figure}



\end{document}